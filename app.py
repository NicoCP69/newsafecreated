import os
import requests
import logging
import csv
from datetime import datetime
from dotenv import load_dotenv
import asyncio
import json
from fastapi import FastAPI, BackgroundTasks, Response
import uvicorn
import threading
import time

# Configuration du logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Chargement des variables d'environnement
load_dotenv()

# Configuration des API
API_KEY = os.getenv("API_KEY")
API_URL = os.getenv("API_URL")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# Initialisation de l'application FastAPI
app = FastAPI(title="BCReader Telegram Bot")

# Configuration de l'API Telegram
TELEGRAM_API_URL = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}"

# Variable globale pour stocker le dernier ID trait√©
last_processed_id = 0

# Verrou pour √©viter les probl√®mes de concurrence
id_lock = threading.Lock()

async def fetch_api_data():
    """R√©cup√®re les donn√©es de l'API BCReader"""
    headers = {
        "accept": "application/json",
        "x-api-key": API_KEY
    }
    
    try:
        response = requests.get(f"{API_URL}/api/config/addresses", headers=headers)
        response.raise_for_status()
        data = response.json()
        logger.info(f"Donn√©es r√©cup√©r√©es avec succ√®s depuis l'API, type: {type(data)}")
        return data
    except requests.exceptions.RequestException as e:
        logger.error(f"Erreur lors de la requ√™te API: {e}")
        return {"error": str(e)}

async def fetch_transactions_data(page=1, limit=20):
    """R√©cup√®re les donn√©es de transactions depuis l'API BCReader"""
    headers = {
        "accept": "application/json",
        "x-api-key": API_KEY
    }
    
    try:
        response = requests.get(f"{API_URL}/api/all-transactions?page={page}&limit={limit}", headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logger.error(f"Erreur lors de la requ√™te API pour les transactions: {e}")
        return {"error": str(e)}

def extract_data_for_csv(data):
    """Extrait les donn√©es pertinentes pour le CSV (id, address, issuer)"""
    csv_data = []
    
    # V√©rification si les donn√©es sont une liste d'objets (comme dans la r√©ponse de l'API)
    if isinstance(data, list):
        for item in data:
            if isinstance(item, dict) and all(k in item for k in ["id", "address"]):
                csv_data.append({
                    "id": item["id"],
                    "address": item["address"],
                    "issuer": item.get("issuer", "")
                })
    # Si les donn√©es sont un dictionnaire
    elif isinstance(data, dict) and not "error" in data:
        # V√©rifier si les adresses sont directement dans une cl√© 'addresses'
        if "addresses" in data and isinstance(data["addresses"], dict):
            for address_id, address_info in data["addresses"].items():
                if isinstance(address_info, dict) and "address" in address_info:
                    csv_data.append({
                        "id": address_id,
                        "address": address_info["address"],
                        "issuer": address_info.get("issuer", "")
                    })
        # Si les donn√©es sont dans une propri√©t√© 'items' ou similaire
        elif "items" in data and isinstance(data["items"], list):
            for item in data["items"]:
                if all(k in item for k in ["id", "address"]):
                    csv_data.append({
                        "id": item["id"],
                        "address": item["address"],
                        "issuer": item.get("issuer", "")
                    })
        # Si les donn√©es sont un objet avec des propri√©t√©s
        else:
            for key, value in data.items():
                if isinstance(value, dict) and all(k in value for k in ["id", "address"]):
                    csv_data.append({
                        "id": value["id"],
                        "address": value["address"],
                        "issuer": value.get("issuer", "")
                    })
                elif isinstance(value, dict) and "address" in value:
                    # Cas o√π l'ID est la cl√© et les autres infos sont dans la valeur
                    csv_data.append({
                        "id": key,
                        "address": value.get("address", ""),
                        "issuer": value.get("issuer", "")
                    })
    
    return csv_data

def save_to_csv(data, keep_file=False):
    """Sauvegarde les donn√©es dans un fichier CSV
    
    Args:
        data: Les donn√©es √† sauvegarder
        keep_file: Si True, conserve le fichier. Si False, le fichier sera temporaire.
        
    Returns:
        Le chemin du fichier CSV cr√©√©
    """
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bcreader_data_{timestamp}.csv"
        filepath = os.path.join(os.path.dirname(__file__), filename)
        
        with open(filepath, 'w', newline='') as csvfile:
            fieldnames = ['id', 'address', 'issuer']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for item in data:
                writer.writerow(item)
        
        logger.info(f"Donn√©es sauvegard√©es dans {filepath}")
        return filepath
    except Exception as e:
        logger.error(f"Erreur lors de la sauvegarde du CSV: {e}")
        return None

def delete_csv_file(filepath):
    """Supprime un fichier CSV"""
    try:
        if filepath and os.path.exists(filepath):
            os.remove(filepath)
            logger.info(f"Fichier supprim√©: {filepath}")
    except Exception as e:
        logger.error(f"Erreur lors de la suppression du fichier: {e}")

def format_data(data, min_id=170, max_addresses=10):
    """Met en forme les donn√©es pour l'affichage dans Telegram"""
    try:
        if not data:
            return "‚ùó Aucune donn√©e disponible"
        
        # S'assurer que min_id est un entier
        min_id = int(min_id) if min_id is not None else 170
        
        # Filtrer les donn√©es pour ne garder que celles avec un ID sup√©rieur √† min_id
        filtered_data = [item for item in data if int(item['id']) > min_id]
        
        # Trier les donn√©es par ID pour s'assurer qu'elles sont dans l'ordre croissant
        filtered_data.sort(key=lambda x: int(x['id']))
        
        if not filtered_data:
            return "‚ÑπÔ∏è Aucune nouvelle adresse depuis le dernier ID"
        
        # Limiter le nombre d'adresses pour √©viter les messages trop longs
        if len(filtered_data) > max_addresses:
            logger.info(f"Limitation √† {max_addresses} adresses sur {len(filtered_data)} d√©tect√©es")
            filtered_data = filtered_data[:max_addresses]
            
        message = "üìä New Safe Deployed üìä\n\n"
        
        for item in filtered_data:
            message += f"üîπ ID: {item['id']}\n"
            message += f"üìç Address: {item['address']}\n"
            message += f"üè¢ Issuer: {item['issuer']}\n\n"
        
        logger.info(f"Formatage de {len(filtered_data)} nouvelles adresses avec ID > {min_id}")
        return message
    except Exception as e:
        logger.error(f"Erreur lors du formatage du message Telegram: {e}")
        return f"‚ùó Erreur de formatage: {str(e)}"

def format_transactions(transactions_data, last_tx_hash=None):
    """Met en forme les donn√©es de transactions pour l'affichage dans Telegram"""
    try:
        if not transactions_data or "data" not in transactions_data or not transactions_data["data"]:
            return "‚ùó Aucune transaction disponible"
        
        # R√©cup√©rer les transactions
        transactions = transactions_data["data"]
        
        # Filtrer les transactions si un hash de derni√®re transaction est fourni
        # Note: Comme l'API ne fournit pas de hash de transaction, nous utilisons une combinaison de from+to+value comme identifiant unique
        if last_tx_hash:
            # Trouver l'index de la derni√®re transaction trait√©e
            try:
                found = False
                filtered_transactions = []
                
                for tx in transactions:
                    tx_hash = f"{tx['from']}_{tx['to']}_{tx['valueFormatted']}"
                    
                    # Si on trouve la transaction d√©j√† trait√©e, on marque qu'on l'a trouv√©e
                    # et on ne l'ajoute pas √† la liste filtr√©e
                    if tx_hash == last_tx_hash:
                        found = True
                        logger.info(f"Transaction d√©j√† trait√©e trouv√©e: {tx_hash}")
                        break
                    
                    # On ajoute uniquement les transactions qui n'ont pas encore √©t√© trait√©es
                    filtered_transactions.append(tx)
                
                # Remplacer la liste originale par la liste filtr√©e
                transactions = filtered_transactions
            except Exception as e:
                logger.error(f"Erreur lors du filtrage des transactions: {e}")
        
        if not transactions:
            return "‚ÑπÔ∏è Aucune nouvelle transaction depuis la derni√®re v√©rification"
            
        message = "üí∞ Nouvelles Transactions üí∞\n\n"
        
        for tx in transactions:
            # V√©rifier si l'adresse d'origine est l'adresse sp√©ciale
            if tx['from'] == "0x74a9b04c7bab3d3BAd1A0a06589A24A67a6f9127":
                message += f"üéÅ *GIFT NEW WALLET* üéÅ üí∏\n"
            else:
                message += f"üîπ De: {tx['from']}\n"
            message += f"üìç √Ä: {tx['to']}\n"
            message += f"üí∂ Montant: {tx['valueFormatted']} {tx['tokenSymbol']}\n\n"
        
        logger.info(f"Formatage de {len(transactions)} nouvelles transactions")
        return message
    except Exception as e:
        logger.error(f"Erreur lors du formatage des transactions pour Telegram: {e}")
        return f"‚ùó Erreur de formatage des transactions: {str(e)}"

async def send_telegram_message(message):
    """Envoie un message via l'API Telegram"""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("Token du bot Telegram non configur√©, impossible d'envoyer le message")
        return False
        
    if not TELEGRAM_CHAT_ID:
        logger.error("ID de chat Telegram non configur√©, impossible d'envoyer le message")
        return False
    
    url = f"{TELEGRAM_API_URL}/sendMessage"
    data = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown"
    }
    
    logger.info(f"Envoi du message Telegram √† l'URL: {url}")
    logger.info(f"Donn√©es: {data}")
    
    try:
        response = requests.post(url, json=data)
        response_json = response.json()
        
        if response.status_code == 200 and response_json.get('ok'):
            logger.info(f"Message envoy√© avec succ√®s sur Telegram au chat {TELEGRAM_CHAT_ID}")
            return True
        else:
            logger.error(f"Erreur Telegram: {response.status_code} - {response_json}")
            return False
    except requests.exceptions.RequestException as e:
        logger.error(f"Erreur lors de l'envoi du message Telegram: {e}")
        if hasattr(e, 'response') and e.response:
            try:
                error_detail = e.response.json()
                logger.error(f"D√©tails de l'erreur: {error_detail}")
            except:
                logger.error(f"Contenu de la r√©ponse: {e.response.text}")
        return False

async def process_and_send_data(min_id=None):
    """R√©cup√®re les donn√©es, les formate et les envoie via Telegram"""
    global last_processed_id
    csv_file = None
    
    try:
        # Si min_id n'est pas sp√©cifi√©, utiliser le dernier ID trait√©
        if min_id is None:
            with id_lock:
                min_id = last_processed_id
                logger.info(f"Utilisation du dernier ID trait√©: {min_id}")
        else:
            logger.info(f"Utilisation de l'ID sp√©cifi√©: {min_id}")
        
        # V√©rification si c'est le premier d√©marrage apr√®s une mise √† jour du code
        # On continue le traitement m√™me au premier d√©marrage pour v√©rifier les nouvelles adresses
        logger.info("V√©rification des nouvelles adresses, m√™me au premier d√©marrage")
            
        # R√©cup√©ration des donn√©es
        data = await fetch_api_data()
        if not data:
            logger.error("Aucune donn√©e re√ßue de l'API")
            return False
        
        # Log pour d√©boguer la structure des donn√©es re√ßues
        logger.info(f"Structure des donn√©es re√ßues: {type(data)}")
        if isinstance(data, dict):
            logger.info(f"Cl√©s dans les donn√©es: {list(data.keys())}")
            if "addresses" in data:
                logger.info(f"Type de 'addresses': {type(data['addresses'])}")
                if isinstance(data['addresses'], dict):
                    logger.info(f"Nombre d'adresses: {len(data['addresses'])}")
                    # Afficher quelques exemples d'adresses
                    sample_keys = list(data['addresses'].keys())[:2]
                    for key in sample_keys:
                        logger.info(f"Exemple d'adresse - Cl√©: {key}, Valeur: {data['addresses'][key]}")
        
        # Extraction des donn√©es pour CSV
        csv_data = extract_data_for_csv(data)
        logger.info(f"Nombre d'adresses extraites pour CSV: {len(csv_data) if csv_data else 0}")
        
        if not csv_data:
            logger.error("Aucune donn√©e extraite pour le CSV")
            return False
        
        # Afficher quelques exemples d'adresses extraites
        for i, item in enumerate(csv_data[:2]):
            logger.info(f"Exemple d'adresse extraite {i+1}: {item}")
        
        # Sauvegarde des donn√©es dans un fichier CSV temporaire
        csv_file = save_to_csv(csv_data, keep_file=False)
        
        # Formatage du message avec filtrage par ID
        message = format_data(csv_data, min_id)
        
        # Envoi du message via Telegram seulement s'il y a de nouvelles donn√©es
        if "Aucune nouvelle adresse" not in message:
            # Trouver le plus grand ID dans les donn√©es filtr√©es
            filtered_data = [item for item in csv_data if int(item['id']) > int(min_id)]
            logger.info(f"Nombre d'adresses apr√®s filtrage (ID > {min_id}): {len(filtered_data)}")
            
            if filtered_data:
                # Afficher quelques exemples d'adresses filtr√©es
                for i, item in enumerate(filtered_data[:2]):
                    logger.info(f"Exemple d'adresse filtr√©e {i+1}: {item}")
                
                max_id = max([int(item['id']) for item in filtered_data])
                logger.info(f"Nouvel ID maximum d√©tect√©: {max_id}")
                
                # Envoyer le message
                success = await send_telegram_message(message)
                logger.info(f"R√©sultat de l'envoi du message: {'Succ√®s' if success else '√âchec'}")
                
                # Mettre √† jour le dernier ID trait√© seulement si l'envoi a r√©ussi
                if success:
                    with id_lock:
                        last_processed_id = max_id
                    logger.info(f"Dernier ID trait√© mis √† jour: {last_processed_id}")
                
                # Supprimer le fichier CSV temporaire apr√®s l'envoi du message
                if csv_file:
                    delete_csv_file(csv_file)
                    
                return success
            else:
                logger.info("Aucune nouvelle adresse apr√®s filtrage")
                if csv_file:
                    delete_csv_file(csv_file)
                return True
        else:
            logger.info("Aucune nouvelle adresse √† envoyer")
            # Supprimer le fichier CSV temporaire s'il n'y a pas de nouvelles donn√©es
            if csv_file:
                delete_csv_file(csv_file)
            return True
    except Exception as e:
        logger.error(f"Erreur lors du traitement et de l'envoi des donn√©es: {e}")
        # Supprimer le fichier CSV temporaire en cas d'erreur
        if csv_file:
            delete_csv_file(csv_file)
        return False

# Variable globale pour stocker le hash de la derni√®re transaction trait√©e
last_transaction_hash = None

# Verrou pour √©viter les probl√®mes de concurrence avec les transactions
tx_lock = threading.Lock()

async def process_and_send_transactions():
    """R√©cup√®re les transactions, les formate et les envoie via Telegram"""
    global last_transaction_hash
    
    try:
        # R√©cup√©ration des donn√©es de transactions
        with tx_lock:
            current_last_tx_hash = last_transaction_hash
            
        logger.info(f"V√©rification des nouvelles transactions depuis le hash: {current_last_tx_hash}")
        
        # M√™me au premier d√©marrage, on v√©rifie les nouvelles transactions
        logger.info("V√©rification des nouvelles transactions, m√™me au premier d√©marrage")
        
        # R√©cup√©ration des donn√©es
        transactions_data = await fetch_transactions_data(page=1, limit=20)
        if not transactions_data or "error" in transactions_data:
            logger.error("Aucune donn√©e de transaction re√ßue de l'API")
            return False
        
        # Formatage du message avec filtrage par hash de transaction
        message = format_transactions(transactions_data, current_last_tx_hash)
        
        # Envoi du message via Telegram seulement s'il y a de nouvelles transactions
        if "Aucune nouvelle transaction" not in message:
            # Envoyer le message
            success = await send_telegram_message(message)
            
            # Mettre √† jour le dernier hash de transaction trait√© seulement si l'envoi a r√©ussi
            if success and transactions_data["data"]:
                # Prendre le hash de la premi√®re transaction (la plus r√©cente) comme nouveau dernier hash
                # Les transactions sont g√©n√©ralement tri√©es par ordre chronologique inverse (la plus r√©cente en premier)
                first_tx = transactions_data["data"][0]
                new_tx_hash = f"{first_tx['from']}_{first_tx['to']}_{first_tx['valueFormatted']}"
                
                with tx_lock:
                    last_transaction_hash = new_tx_hash
                logger.info(f"Dernier hash de transaction mis √† jour: {last_transaction_hash}")
                logger.info(f"M√©moris√© pour √©viter les doublons: {len(transactions_data['data'])} transactions trait√©es")
                
                return success
            else:
                logger.info("Aucune nouvelle transaction apr√®s filtrage ou √©chec d'envoi")
                return False
        else:
            logger.info("Aucune nouvelle transaction √† envoyer")
            return True
    except Exception as e:
        logger.error(f"Erreur lors du traitement et de l'envoi des transactions: {e}")
        return False

@app.get("/")
async def root():
    return {"message": "BCReader Telegram Bot API"}

@app.get("/send-update")
async def send_update(background_tasks: BackgroundTasks, min_id: int = None):
    """D√©clenche l'envoi d'une mise √† jour via Telegram"""
    # Si min_id n'est pas sp√©cifi√©, on utilisera le dernier ID trait√© dans process_and_send_data
    background_tasks.add_task(process_and_send_data, min_id)
    
    if min_id is None:
        with id_lock:
            current_id = last_processed_id
        return {"message": f"Mise √† jour en cours d'envoi (adresses avec ID > {current_id})"}    
    else:
        return {"message": f"Mise √† jour en cours d'envoi (adresses avec ID > {min_id})"}

@app.get("/send-transactions-update")
async def send_transactions_update(background_tasks: BackgroundTasks):
    """D√©clenche l'envoi d'une mise √† jour des transactions via Telegram"""
    background_tasks.add_task(process_and_send_transactions)
    
    with tx_lock:
        current_hash = last_transaction_hash
    
    if current_hash:
        return {"message": f"Mise √† jour des transactions en cours d'envoi (depuis le hash {current_hash[:15]}...)"}    
    else:
        return {"message": "Premi√®re mise √† jour des transactions en cours d'envoi"}

@app.get("/get-csv")
async def get_csv():
    """Endpoint pour g√©n√©rer et t√©l√©charger un fichier CSV des donn√©es actuelles"""
    try:
        # R√©cup√©ration des donn√©es
        data = await fetch_api_data()
        if not data:
            return Response(content="Aucune donn√©e disponible", media_type="text/plain")
            
        # Extraction des donn√©es pour CSV
        csv_data = extract_data_for_csv(data)
        if not csv_data:
            return Response(content="Aucune donn√©e extraite pour le CSV", media_type="text/plain")
        
        # G√©n√©ration du CSV avec keep_file=True pour conserver le fichier
        csv_file = save_to_csv(csv_data, keep_file=True)
        
        if not csv_file:
            return Response(content="Impossible de g√©n√©rer le fichier CSV", media_type="text/plain", status_code=500)
        
        # Lecture du contenu du fichier CSV
        with open(csv_file, 'r', encoding='utf-8') as f:
            csv_content = f.read()
        
        # Cr√©ation de la r√©ponse avec le contenu CSV
        response = Response(content=csv_content)
        response.headers["Content-Disposition"] = f"attachment; filename={os.path.basename(csv_file)}"
        response.headers["Content-Type"] = "text/csv"
        
        return response
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration du CSV: {e}")
        return Response(content=f"Erreur: {str(e)}", media_type="text/plain", status_code=500)

def periodic_check():
    """Fonction ex√©cut√©e p√©riodiquement pour v√©rifier les nouvelles adresses et transactions"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    while True:
        try:
            # V√©rification des nouvelles adresses
            logger.info("V√©rification p√©riodique des nouvelles adresses...")
            loop.run_until_complete(process_and_send_data())
            
            # V√©rification des nouvelles transactions
            logger.info("V√©rification p√©riodique des nouvelles transactions...")
            loop.run_until_complete(process_and_send_transactions())
            
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification p√©riodique: {e}")
        
        # Attendre 60 secondes avant la prochaine v√©rification
        time.sleep(60)

@app.on_event("startup")
async def startup_event():
    """Ex√©cut√© au d√©marrage de l'application"""
    logger.info("Application d√©marr√©e")
    
    # Initialiser le dernier ID trait√© √† une valeur qui permettra de d√©tecter les nouvelles adresses
    global last_processed_id, last_transaction_hash
    last_processed_id = 0  # Valeur basse pour d√©tecter les nouvelles adresses
    logger.info(f"Dernier ID trait√© initialis√© √†: {last_processed_id}")
    
    # Initialiser le hash de la derni√®re transaction √† None pour d√©tecter les nouvelles transactions
    last_transaction_hash = None
    logger.info("Hash de la derni√®re transaction initialis√© √† None pour d√©tecter les nouvelles transactions")
    
    # D√©marrer la v√©rification p√©riodique dans un thread s√©par√©
    thread = threading.Thread(target=periodic_check, daemon=True)
    thread.start()
    logger.info("V√©rification p√©riodique d√©marr√©e (toutes les 60 secondes)")
    logger.info("Surveillance des nouvelles adresses ET transactions activ√©e")


if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)
